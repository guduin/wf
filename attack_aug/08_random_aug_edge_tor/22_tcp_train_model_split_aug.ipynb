{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c831490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import adam_v2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e510979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5140bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('F:/data_edge/3_data/data.csv', header=None)\n",
    "df = df.sort_values([1, 0])\n",
    "\n",
    "train = np.array(df[0 : 7000].sample(7000))\n",
    "train_data = train[:, 2:502] # shape (7000, 500), 100 website, 70 repeat\n",
    "train_index = train[:, 0] # shape (7000,), 0-99 range, random\n",
    "\n",
    "test = np.array(df[7000 : 10000].sort_values([0, 1]))\n",
    "test_data = test[:, 2:502] # shape (3000, 500), 100 website, 70 repeat\n",
    "test_index = test[:, 0] # shape (3000,), 0-99 range, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ce90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_length(data_vector):\n",
    "    data_length = 500\n",
    "    for i in range(500):\n",
    "        if data_vector[i] == 0:\n",
    "            data_length = i\n",
    "            break\n",
    "    return data_length\n",
    "\n",
    "def add_noise(data_vector, data_length, count):\n",
    "    for i in range(count):\n",
    "        location = random.randint(0, data_length - 1)\n",
    "        first = second = 0\n",
    "        if data_vector[location] > 5:\n",
    "            first = random.randint(1, data_vector[location] - 1)\n",
    "            second = data_vector[location] - first\n",
    "        elif data_vector[location] < -5:\n",
    "            first = random.randint(data_vector[location] + 1, -1)\n",
    "            second = data_vector[location] - first\n",
    "        data_vector[location] = second\n",
    "        data_vector = np.insert(data_vector, location, first)\n",
    "        if data_length < 500:\n",
    "            data_length += 1\n",
    "    return data_vector[0 : 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053cc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = train_data.copy()\n",
    "train_index_aug = train_index.copy()\n",
    "for j in range(5):\n",
    "    train_data_aug_one = train_data.copy()\n",
    "    for i in range(7000):\n",
    "        length = get_data_length(train_data_aug_one[i])\n",
    "        rate = random.randint(0, 100) / 100\n",
    "        train_data_aug_one[i] = add_noise(train_data_aug_one[i], length, int(length * rate))\n",
    "    train_data_aug = np.append(train_data_aug, train_data_aug_one, axis=0)\n",
    "    train_index_aug = np.append(train_index_aug, train_index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db277a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Sequential()\n",
    "model.add(Conv1D(input_shape = (500, 1),\n",
    "                 filters=32,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 strides=1,\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=32,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 strides=1,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=128,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=256,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=256,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam_v2.Adam(learning_rate=0.001),\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4398969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "919/919 [==============================] - 91s 99ms/step - loss: 1.5056 - accuracy: 0.5985 - val_loss: 0.4256 - val_accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "919/919 [==============================] - 91s 99ms/step - loss: 0.2713 - accuracy: 0.9178 - val_loss: 0.2911 - val_accuracy: 0.9110\n",
      "Epoch 3/10\n",
      "919/919 [==============================] - 91s 99ms/step - loss: 0.1524 - accuracy: 0.9525 - val_loss: 0.2769 - val_accuracy: 0.9224\n",
      "Epoch 4/10\n",
      "919/919 [==============================] - 91s 99ms/step - loss: 0.1021 - accuracy: 0.9678 - val_loss: 0.1886 - val_accuracy: 0.9436\n",
      "Epoch 5/10\n",
      "919/919 [==============================] - 90s 98ms/step - loss: 0.0817 - accuracy: 0.9736 - val_loss: 0.1721 - val_accuracy: 0.9543\n",
      "Epoch 6/10\n",
      "919/919 [==============================] - 90s 97ms/step - loss: 0.0631 - accuracy: 0.9787 - val_loss: 0.2158 - val_accuracy: 0.9441\n",
      "Epoch 7/10\n",
      "919/919 [==============================] - 90s 98ms/step - loss: 0.0580 - accuracy: 0.9814 - val_loss: 0.1619 - val_accuracy: 0.9596\n",
      "Epoch 8/10\n",
      "919/919 [==============================] - 90s 98ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.1701 - val_accuracy: 0.9598\n",
      "Epoch 9/10\n",
      "919/919 [==============================] - 90s 98ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.1323 - val_accuracy: 0.9625\n",
      "Epoch 10/10\n",
      "919/919 [==============================] - 90s 98ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.1692 - val_accuracy: 0.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd826b4648>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_aug.astype('float32')/1600, to_categorical(train_index_aug), epochs = 10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1686907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1377 - accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1377158761024475, 0.9763333201408386]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data.astype('float32')/1600, to_categorical(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbeffb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('data/model_tcp_split_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d811aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f86ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
