{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c831490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import adam_v2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e510979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5140bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/F/data_edge/3_data/data.csv', header=None)\n",
    "df = df.sort_values([1, 0])\n",
    "\n",
    "train = np.array(df[0 : 7000].sample(7000))\n",
    "train_data = train[:, 2:502] # shape (7000, 500), 100 website, 70 repeat\n",
    "train_index = train[:, 0] # shape (7000,), 0-99 range, random\n",
    "\n",
    "test = np.array(df[7000 : 10000].sort_values([0, 1]))\n",
    "test_data = test[:, 2:502] # shape (3000, 500), 100 website, 70 repeat\n",
    "test_index = test[:, 0] # shape (3000,), 0-99 range, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ce90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_length(data_vector):\n",
    "    data_length = 500\n",
    "    for i in range(500):\n",
    "        if data_vector[i] == 0:\n",
    "            data_length = i\n",
    "            break\n",
    "    return data_length\n",
    "\n",
    "def add_noise(data_vector, data_length, count):\n",
    "    for i in range(count):\n",
    "        location = random.randint(0, data_length - 1)\n",
    "        first = second = 0\n",
    "        if data_vector[location] > 5:\n",
    "            first = random.randint(1, data_vector[location] - 1)\n",
    "            second = data_vector[location] - first\n",
    "        elif data_vector[location] < -5:\n",
    "            first = random.randint(data_vector[location] + 1, -1)\n",
    "            second = data_vector[location] - first\n",
    "        data_vector[location] = second\n",
    "        data_vector = np.insert(data_vector, location, first)\n",
    "        if data_length < 500:\n",
    "            data_length += 1\n",
    "    return data_vector[0 : 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053cc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = train_data.copy()\n",
    "train_index_aug = train_index.copy()\n",
    "for j in range(6):\n",
    "    train_data_aug_one = train_data.copy()\n",
    "    for i in range(7000):\n",
    "        length = get_data_length(train_data_aug_one[i])\n",
    "        rate = random.randint(0, 100) / 100\n",
    "        train_data_aug_one[i] = add_noise(train_data_aug_one[i], length, int(length * rate))\n",
    "    train_data_aug = np.append(train_data_aug, train_data_aug_one, axis=0)\n",
    "    train_index_aug = np.append(train_index_aug, train_index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db277a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Sequential()\n",
    "model.add(Conv1D(input_shape = (500, 1),\n",
    "                 filters=32,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 strides=1,\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=32,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 strides=1,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=64,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=128,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=256,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=256,\n",
    "                 kernel_size=5,\n",
    "                 padding = 'same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam_v2.Adam(learning_rate=0.001),\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4398969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1072/1072 [==============================] - 116s 107ms/step - loss: 1.3803 - accuracy: 0.6312 - val_loss: 0.5347 - val_accuracy: 0.8400\n",
      "Epoch 2/10\n",
      "1072/1072 [==============================] - 112s 105ms/step - loss: 0.2395 - accuracy: 0.9274 - val_loss: 0.2179 - val_accuracy: 0.9319\n",
      "Epoch 3/10\n",
      "1072/1072 [==============================] - 130s 122ms/step - loss: 0.1334 - accuracy: 0.9566 - val_loss: 0.1540 - val_accuracy: 0.9518\n",
      "Epoch 4/10\n",
      "1072/1072 [==============================] - 170s 159ms/step - loss: 0.0985 - accuracy: 0.9677 - val_loss: 0.1120 - val_accuracy: 0.9682\n",
      "Epoch 5/10\n",
      "1072/1072 [==============================] - 171s 160ms/step - loss: 0.0755 - accuracy: 0.9764 - val_loss: 0.1293 - val_accuracy: 0.9633\n",
      "Epoch 6/10\n",
      "1072/1072 [==============================] - 174s 162ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.0994 - val_accuracy: 0.9705\n",
      "Epoch 7/10\n",
      "1072/1072 [==============================] - 170s 159ms/step - loss: 0.0561 - accuracy: 0.9819 - val_loss: 0.1174 - val_accuracy: 0.9649\n",
      "Epoch 8/10\n",
      "1072/1072 [==============================] - 174s 163ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.0990 - val_accuracy: 0.9714\n",
      "Epoch 9/10\n",
      "1072/1072 [==============================] - 171s 160ms/step - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.1309 - val_accuracy: 0.9665\n",
      "Epoch 10/10\n",
      "1072/1072 [==============================] - 123s 115ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.0891 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eba7ef0088>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_aug.astype('float32')/1600, to_categorical(train_index_aug), epochs = 10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1686907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 3s 32ms/step - loss: 0.1577 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1576675921678543, 0.9800000190734863]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data.astype('float32')/1600, to_categorical(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbeffb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('data/model_tcp_split_aug_repeat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d811aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f86ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
